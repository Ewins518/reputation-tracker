{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "onnx_file_path = \"distilbert_model.onnx\" # .onnx in the same directory\n",
    "ort_session = onnxruntime.InferenceSession(onnx_file_path) \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def preprocess_text(text, max_sequence_length=512):\n",
    "    tokens = tokenizer.encode(text, max_length=max_sequence_length, truncation=True)\n",
    "    padding_length = max_sequence_length - len(tokens)\n",
    "    tokens += [0] * padding_length  # Token d'ID de padding pour BERT\n",
    "    return np.array(tokens).reshape(1, -1)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    input_ids = preprocess_text(text)\n",
    "\n",
    "    ort_inputs = {'input_ids': input_ids}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "    logits = ort_outs[0]\n",
    "    predicted_class = np.argmax(logits, axis=1).item()\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment positif\n"
     ]
    }
   ],
   "source": [
    "test_text = \"This product exceeded my expectations! \\\n",
    "            It's incredibly effective, and I'm impressed with its quality. \\\n",
    "            I highly recommend it to anyone in need of a reliable solution.\"\n",
    "predicted_sentiment = predict_sentiment(test_text)\n",
    "\n",
    "if predicted_sentiment == 1:\n",
    "    print(\"Sentiment positif\")\n",
    "else:\n",
    "    print(\"Sentiment négatif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment négatif\n"
     ]
    }
   ],
   "source": [
    "test_text = \"I  would not recommend this product. \\\n",
    "            The quality is poor, and it didn't work as expected. \\\n",
    "            I'm very disappointed with the purchase, and I regret buying it.\"\n",
    "predicted_sentiment = predict_sentiment(test_text)\n",
    "\n",
    "if predicted_sentiment == 1:\n",
    "    print(\"Sentiment positif\")\n",
    "else:\n",
    "    print(\"Sentiment négatif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
