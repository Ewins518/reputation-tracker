{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-09T22:45:08.875208Z","iopub.status.busy":"2024-09-09T22:45:08.874820Z","iopub.status.idle":"2024-09-09T22:45:14.136700Z","shell.execute_reply":"2024-09-09T22:45:14.135666Z","shell.execute_reply.started":"2024-09-09T22:45:08.875174Z"},"trusted":true},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np\n","import torch.onnx\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/olivier/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16a5993ac61c4dfb81253fdbb4076bf5","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["## Models alternatifs\n","\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n","\n","\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T22:45:20.375833Z","iopub.status.busy":"2024-09-09T22:45:20.375234Z","iopub.status.idle":"2024-09-09T22:45:28.801792Z","shell.execute_reply":"2024-09-09T22:45:28.800831Z","shell.execute_reply.started":"2024-09-09T22:45:20.375792Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f09e06efb974912b985552e38186675","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4173254778cc428095f5263b0e76d33c","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae258fbde8ed444cbcea3b508a4e11c8","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1eb12e7a91284a6590281a7bedf12549","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45b93eeb4cc3426eb5b215a4ad12c04e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertTokenizer, BertForSequenceClassification\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T22:45:36.384981Z","iopub.status.busy":"2024-09-09T22:45:36.383717Z","iopub.status.idle":"2024-09-09T22:45:36.553389Z","shell.execute_reply":"2024-09-09T22:45:36.552300Z","shell.execute_reply.started":"2024-09-09T22:45:36.384928Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>polarity</th>\n","      <th>recommendations</th>\n","      <th>reviews</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The best soundtrack ever to anything.</td>\n","      <td>I'm reading a lot of reviews saying that this ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Amazing!</td>\n","      <td>This soundtrack is my favorite music of all ti...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Excellent Soundtrack</td>\n","      <td>I truly like this soundtrack and I enjoy video...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n","      <td>If you've played the game, you know how divine...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>an absolute masterpiece</td>\n","      <td>I am quite sure any of you actually taking the...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   polarity                                    recommendations  \\\n","0         1              The best soundtrack ever to anything.   \n","1         1                                           Amazing!   \n","2         1                               Excellent Soundtrack   \n","3         1  Remember, Pull Your Jaw Off The Floor After He...   \n","4         1                            an absolute masterpiece   \n","\n","                                             reviews  \n","0  I'm reading a lot of reviews saying that this ...  \n","1  This soundtrack is my favorite music of all ti...  \n","2  I truly like this soundtrack and I enjoy video...  \n","3  If you've played the game, you know how divine...  \n","4  I am quite sure any of you actually taking the...  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('/kaggle/input/amazon-reviews/train.csv', nrows = 10000)\n","\n","cols = ['polarity', 'recommendations', 'reviews']\n","df.columns = cols\n","\n","df['polarity'] = df['polarity'].replace({1: 0, 2: 1})\n","df.head(5)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T22:45:39.769604Z","iopub.status.busy":"2024-09-09T22:45:39.769204Z","iopub.status.idle":"2024-09-09T22:45:39.782684Z","shell.execute_reply":"2024-09-09T22:45:39.781593Z","shell.execute_reply.started":"2024-09-09T22:45:39.769571Z"},"trusted":true},"outputs":[{"data":{"text/plain":["polarity\n","0    5098\n","1    4902\n","Name: count, dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df[\"polarity\"].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T22:45:44.094225Z","iopub.status.busy":"2024-09-09T22:45:44.093824Z","iopub.status.idle":"2024-09-09T22:46:06.595534Z","shell.execute_reply":"2024-09-09T22:46:06.594442Z","shell.execute_reply.started":"2024-09-09T22:45:44.094193Z"},"trusted":true},"outputs":[],"source":["train_texts = df['reviews'].tolist()\n","train_labels = df['polarity'].tolist()\n","\n","input_ids = tokenizer(train_texts, return_tensors='pt', padding=True, truncation=True)['input_ids']\n","labels = torch.tensor(train_labels)\n","\n","dataset = TensorDataset(input_ids, labels)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Model training"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T22:46:20.861398Z","iopub.status.busy":"2024-09-09T22:46:20.860362Z","iopub.status.idle":"2024-09-09T22:52:04.976019Z","shell.execute_reply":"2024-09-09T22:52:04.974424Z","shell.execute_reply.started":"2024-09-09T22:46:20.861353Z"},"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     23\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.train()\n","model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","\n","accumulation_steps = 4\n","num_epochs = 1 #30\n","correct_predictions = 0\n","total_predictions = 0\n","\n","for epoch in range(num_epochs):\n","    for i, batch in enumerate(dataloader):\n","        inputs, labels = batch\n","        attention_mask = (inputs != tokenizer.pad_token_id).float()\n","        inputs, labels, attention_mask = inputs.to(device), labels.to(device), attention_mask.to(device)\n","        optimizer.zero_grad()\n","\n","        with torch.set_grad_enabled(True):\n","            outputs = model(inputs, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            loss.backward()\n","            logits = outputs.logits\n","            predictions = torch.argmax(logits, dim=1)\n","            correct_predictions += torch.sum(predictions == labels).item()\n","            total_predictions += len(labels)\n","\n","        if (i + 1) % accumulation_steps == 0 or i == len(dataloader) - 1:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        torch.cuda.empty_cache()\n","\n","    accuracy = correct_predictions / total_predictions\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}, Accuracy: {accuracy}')\n","    correct_predictions = 0\n","    total_predictions = 0"]},{"cell_type":"markdown","metadata":{},"source":["## Prediction using the model "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-23T11:46:49.459613Z","iopub.status.idle":"2023-12-23T11:46:49.460083Z","shell.execute_reply":"2023-12-23T11:46:49.459865Z","shell.execute_reply.started":"2023-12-23T11:46:49.459841Z"},"trusted":true},"outputs":[],"source":["df[\"reviews\"][77]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-23T11:46:49.461833Z","iopub.status.idle":"2023-12-23T11:46:49.462314Z","shell.execute_reply":"2023-12-23T11:46:49.462074Z","shell.execute_reply.started":"2023-12-23T11:46:49.462052Z"},"trusted":true},"outputs":[],"source":["test_text = df[\"reviews\"][77]\n","\n","test_input_ids = tokenizer(test_text, return_tensors='pt')['input_ids']\n","test_input_ids = test_input_ids.to(device)\n","\n","with torch.no_grad():\n","    model.eval()\n","    outputs = model(test_input_ids)\n","    logits = outputs.logits\n","    prediction = torch.argmax(logits, dim=1)\n"," \n","    if prediction == 1:\n","        print(\"Sentiment positif\")\n","    else:\n","        print(\"Sentiment négatif\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-23T11:46:49.463353Z","iopub.status.idle":"2023-12-23T11:46:49.463782Z","shell.execute_reply":"2023-12-23T11:46:49.463582Z","shell.execute_reply.started":"2023-12-23T11:46:49.463561Z"},"trusted":true},"outputs":[],"source":["test_text = \"This product is not bad at all\"\n","\n","test_input_ids = tokenizer(test_text, return_tensors='pt')['input_ids']\n","test_input_ids = test_input_ids.to(device)\n","\n","with torch.no_grad():\n","    model.eval()\n","    outputs = model(test_input_ids)\n","    logits = outputs.logits\n","    prediction = torch.argmax(logits, dim=1)\n"," \n","    if prediction == 1:\n","        print(\"Sentiment positif\")\n","    else:\n","        print(\"Sentiment négatif\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-12-23T11:46:49.465598Z","iopub.status.idle":"2023-12-23T11:46:49.465968Z","shell.execute_reply":"2023-12-23T11:46:49.465811Z","shell.execute_reply.started":"2023-12-23T11:46:49.465793Z"},"trusted":true},"outputs":[],"source":["prediction"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------------------------------------------\n","OutOfMemoryError                          Traceback (most recent call last)\n","Cell In[14], line 19\n","     16 optimizer.zero_grad()\n","     18 with torch.set_grad_enabled(True):\n","---> 19     outputs = model(inputs, attention_mask=attention_mask, labels=labels)\n","     20     loss = outputs.loss\n","     21     loss.backward()\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1208, in XLMRobertaForSequenceClassification.forward(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\n","   1200 r\"\"\"\n","   1201 labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n","   1202     Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n","   1203     config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n","   1204     `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","   1205 \"\"\"\n","   1206 return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","-> 1208 outputs = self.roberta(\n","   1209     input_ids,\n","   1210     attention_mask=attention_mask,\n","   1211     token_type_ids=token_type_ids,\n","   1212     position_ids=position_ids,\n","   1213     head_mask=head_mask,\n","   1214     inputs_embeds=inputs_embeds,\n","   1215     output_attentions=output_attentions,\n","   1216     output_hidden_states=output_hidden_states,\n","   1217     return_dict=return_dict,\n","   1218 )\n","   1219 sequence_output = outputs[0]\n","   1220 logits = self.classifier(sequence_output)\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:837, in XLMRobertaModel.forward(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\n","    828 head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n","    830 embedding_output = self.embeddings(\n","    831     input_ids=input_ids,\n","    832     position_ids=position_ids,\n","   (...)\n","    835     past_key_values_length=past_key_values_length,\n","    836 )\n","--> 837 encoder_outputs = self.encoder(\n","    838     embedding_output,\n","    839     attention_mask=extended_attention_mask,\n","    840     head_mask=head_mask,\n","    841     encoder_hidden_states=encoder_hidden_states,\n","    842     encoder_attention_mask=encoder_extended_attention_mask,\n","    843     past_key_values=past_key_values,\n","    844     use_cache=use_cache,\n","    845     output_attentions=output_attentions,\n","    846     output_hidden_states=output_hidden_states,\n","    847     return_dict=return_dict,\n","    848 )\n","    849 sequence_output = encoder_outputs[0]\n","    850 pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:525, in XLMRobertaEncoder.forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\n","    514     layer_outputs = self._gradient_checkpointing_func(\n","    515         layer_module.__call__,\n","    516         hidden_states,\n","   (...)\n","    522         output_attentions,\n","    523     )\n","    524 else:\n","--> 525     layer_outputs = layer_module(\n","    526         hidden_states,\n","    527         attention_mask,\n","    528         layer_head_mask,\n","    529         encoder_hidden_states,\n","    530         encoder_attention_mask,\n","    531         past_key_value,\n","    532         output_attentions,\n","    533     )\n","    535 hidden_states = layer_outputs[0]\n","    536 if use_cache:\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:414, in XLMRobertaLayer.forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\n","    402 def forward(\n","    403     self,\n","    404     hidden_states: torch.Tensor,\n","   (...)\n","    411 ) -> Tuple[torch.Tensor]:\n","    412     # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n","    413     self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n","--> 414     self_attention_outputs = self.attention(\n","    415         hidden_states,\n","    416         attention_mask,\n","    417         head_mask,\n","    418         output_attentions=output_attentions,\n","    419         past_key_value=self_attn_past_key_value,\n","    420     )\n","    421     attention_output = self_attention_outputs[0]\n","    423     # if decoder, the last output is tuple of self-attn cache\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:341, in XLMRobertaAttention.forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\n","    331 def forward(\n","    332     self,\n","    333     hidden_states: torch.Tensor,\n","   (...)\n","    339     output_attentions: Optional[bool] = False,\n","    340 ) -> Tuple[torch.Tensor]:\n","--> 341     self_outputs = self.self(\n","    342         hidden_states,\n","    343         attention_mask,\n","    344         head_mask,\n","    345         encoder_hidden_states,\n","    346         encoder_attention_mask,\n","    347         past_key_value,\n","    348         output_attentions,\n","    349     )\n","    350     attention_output = self.output(self_outputs[0], hidden_states)\n","    351     outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:237, in XLMRobertaSelfAttention.forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\n","    234     past_key_value = (key_layer, value_layer)\n","    236 # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n","--> 237 attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n","    239 if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n","    240     query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n","\n","OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 15.90 GiB total capacity; 14.68 GiB already allocated; 45.75 MiB free; 15.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF## .onnx generation"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T11:27:23.461397Z","iopub.status.busy":"2023-12-23T11:27:23.460538Z","iopub.status.idle":"2023-12-23T11:27:31.393194Z","shell.execute_reply":"2023-12-23T11:27:31.392252Z","shell.execute_reply.started":"2023-12-23T11:27:23.461362Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n","ONNX model saved at: /kaggle/working/roberta.onnx\n"]}],"source":["model.eval()\n","batch_size = 32\n","max_sequence_length = 512\n","\n","onnx_file_path = \"/kaggle/working/xlm_r.onnx\"\n","dummy_input = torch.ones(1, max_sequence_length, dtype=torch.long).to(model.device)\n","dynamic_axes = {'input_ids': {0: 'batch_size', 1: 'sequence_length'}}\n","\n","torch.onnx.export(model, dummy_input, onnx_file_path, verbose=True, input_names=['input_ids'], output_names=['logits'], dynamic_axes=dynamic_axes)\n","print(f\"ONNX model saved at: {onnx_file_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1340369,"sourceId":2233682,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
